{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f723b4ab",
   "metadata": {},
   "source": [
    "Load the Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d323af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import os\n",
    "import numpy as np \n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nilearn import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04caea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Path to the data\n",
    "\n",
    "datapath='/data/neuromark2/Data/ABCD/Data_BIDS_5/Raw_Data/'\n",
    "\n",
    "SubIDs=os.listdir(datapath)\n",
    "\n",
    "timepoint=\"/Baseline/\"\n",
    "len(SubIDs)\n",
    "\n",
    "#Get the foldernames from the SubIDs\n",
    "dict1={}\n",
    "\n",
    "for s in SubIDs:\n",
    "    try:\n",
    "        folder=os.listdir(datapath+s+timepoint)\n",
    "        for f in folder:\n",
    "            if 'anat' in f and 'NORM' not in f:\n",
    "                dict1[s]=[f]\n",
    "                break\n",
    "            if 'anat' in f:\n",
    "                dict1[s]=[f]\n",
    "    except:\n",
    "        print(\"Path not found\",s)\n",
    "        pass\n",
    "print(len(dict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125383ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# QC data\n",
    "df = pd.read_csv(\"/data/neuromark2/Data/ABCD/Data_info/Demo51/abcd-data-release-5.1/core/imaging/mri_y_qc_incl.csv\")  \n",
    "df1=df[df['eventname']=='baseline_year_1_arm_1']\n",
    "qc_df=df1[['src_subject_id','imgincl_t1w_include']]\n",
    "print(qc_df.shape)\n",
    "\n",
    "#CBCL data\n",
    "df = pd.read_csv(\"/data/neuromark2/Data/ABCD/Data_info/Demo51/abcd-data-release-5.1/core/mental-health/mh_p_cbcl.csv\")  \n",
    "df1=df[df['eventname']=='baseline_year_1_arm_1']\n",
    "cbcl_df=df1[['src_subject_id','cbcl_scr_syn_anxdep_r']]\n",
    "print(cbcl_df.shape)\n",
    "\n",
    "#Gender data\n",
    "df = pd.read_csv(\"/data/neuromark2/Data/ABCD/Data_info/Demo51/abcd-data-release-5.1/core/abcd-general/abcd_p_demo.csv\")\n",
    "df1=df[df['eventname']=='baseline_year_1_arm_1']\n",
    "gender_df=df1[['src_subject_id','demo_sex_v2']]\n",
    "print(gender_df.shape)\n",
    "\n",
    "#Site data\n",
    "df = pd.read_csv(\"/data/neuromark2/Data/ABCD/Data_info/Demo51/abcd-data-release-5.1/core/abcd-general/abcd_y_lt.csv\")\n",
    "df1=df[df['eventname']=='baseline_year_1_arm_1']\n",
    "site_df=df1[['src_subject_id','site_id_l','interview_age]]\n",
    "print(site_df.shape)\n",
    "\n",
    "#Merge these based on the subject ids\n",
    "merged_df1=pd.merge(qc_df,cbcl_df,on='src_subject_id',how='inner')\n",
    "merged_df2=pd.merge(gender_df,site_df,on='src_subject_id',how='inner')\n",
    "merged_df=pd.merge(merged_df1,merged_df2,on='src_subject_id',how='inner')\n",
    "merged_df['src_subject_id']=merged_df['src_subject_id'].str.replace('_','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03915efb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dict_df = pd.DataFrame.from_dict(dict1, orient='index',columns=['scan_session'])\n",
    "\n",
    "dict_df['src_subject_id'] = dict_df.index\n",
    "\n",
    "dict_df = dict_df.reset_index(drop=True)\n",
    "\n",
    "final_df = pd.merge(merged_df, dict_df,on='src_subject_id',how='inner')\n",
    "\n",
    "filename='Data.csv'\n",
    "final_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c83e3",
   "metadata": {},
   "source": [
    "Create mean image and mask from first 1000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275853d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data.csv\")  \n",
    "df=df[df['imgincl_t1w_include']==1]\n",
    "df=df[:1000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a9ef4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create (121,145,121,subjects) image\n",
    "images=[]\n",
    "for _,s in df.iterrows():\n",
    "    d=s['src_subject_id']\n",
    "    t=s['scan_session']\n",
    "    path=datapath+d+timepoint+t\n",
    "    file_path=os.path.join(path,'smwc1pT1.nii')\n",
    "    images.append(nib.load(file_path).get_fdata()) \n",
    "stacked_image = np.stack(images, axis=-1) \n",
    "\n",
    "print(stacked_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c25634",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Save the image\n",
    "d = df.iloc[0]['src_subject_id']\n",
    "t = df.iloc[0]['scan_session']\n",
    "path=datapath+d+timepoint+t\n",
    "first_img = nib.load(os.path.join(path,'smwc1pT1.nii')) # load the first image to get the header\n",
    "stacked_nii_img = nib.Nifti1Image(stacked_image, first_img.affine, header=first_img.header)\n",
    "nib.save(stacked_nii_img,'stacked_image.nii')\n",
    "print(stacked_nii_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01cf2d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Generating mean image and save it\n",
    "mean_img = image.mean_img(\"stacked_image.nii\")\n",
    "print(mean_img)  \n",
    "print(\"Shape:\", mean_img.shape)  \n",
    "print(\"Affine:\\n\", mean_img.affine)\n",
    "\n",
    "nib.save(mean_img,'mean_image.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a12b4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "mean_img=image.mean_img(\"mean_image.nii\")\n",
    "mean_data = mean_img.get_fdata().flatten()\n",
    "\n",
    "# Compute correlation for each image\n",
    "images=[]\n",
    "meta_data=[]\n",
    "for _,s in df.iterrows():\n",
    "    d=s['src_subject_id']\n",
    "    t=s['scan_session']\n",
    "    path=datapath+d+timepoint+t\n",
    "    file_path=os.path.join(path,'smwc1pT1.nii')\n",
    "    img=nib.load(file_path).get_fdata()\n",
    "    img_data = img.flatten()  # Flatten current image\n",
    "    corr, _ = pearsonr(img_data, mean_data)  # Compute Pearson correlation\n",
    "    if corr>0.85:\n",
    "        images.append(nib.load(file_path).get_fdata())\n",
    "        meta_data.append(s)\n",
    "print(len(images))\n",
    "print(len(meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d273d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corr_stacked_image = np.stack(images, axis=-1) \n",
    "print(corr_stacked_image.shape)\n",
    "d = df.iloc[0]['src_subject_id']\n",
    "t = df.iloc[0]['scan_session']\n",
    "path=datapath+d+timepoint+t\n",
    "first_img = nib.load(os.path.join(path,'smwc1pT1.nii')) # load the first image to get the header\n",
    "corr_stacked_nii_img = nib.Nifti1Image(corr_stacked_image, first_img.affine, header=first_img.header)\n",
    "nib.save(corr_stacked_nii_img,'corr_stacked_image.nii')\n",
    "print(corr_stacked_nii_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b4d40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smri_4d = image.load_img(\"corr_stacked_image.nii\")\n",
    "smri_data = smri_4d.get_fdata()\n",
    "x_dim, y_dim, z_dim, subjects= smri_data.shape\n",
    "\n",
    "print(smri_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e1b28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "average_map = np.mean(smri_data, axis=-1)\n",
    "d = df.iloc[0]['src_subject_id']\n",
    "t = df.iloc[0]['scan_session']\n",
    "path=datapath+d+timepoint+t\n",
    "first_img = nib.load(os.path.join(path,'smwc1pT1.nii')) # load the first image to get the header\n",
    "average_img = nib.Nifti1Image(average_map,first_img.affine,header=first_img.header)\n",
    "nib.save(average_img, 'average_map.nii')\n",
    "plotting.view_img(average_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960a74a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "\n",
    "img = nib.load(\"average_map.nii\")  \n",
    "data = img.get_fdata()\n",
    "plotting.view_img(img)\n",
    "\n",
    "# Apply threshold to create a binary mask\n",
    "threshold = 0.2\n",
    "mask = (data > threshold).astype(np.uint8)  # 1 where data > 0.2, else 0\n",
    "\n",
    "mask_nifti = nib.Nifti1Image(mask, img.affine, img.header)\n",
    "nib.save(mask_nifti, \"mask.nii\")\n",
    "plotting.view_img(mask_nifti)\n",
    "\n",
    "# Visualize the middle slice\n",
    "slice_idx = data.shape[-1] // 2  # Select a middle slice for visualization\n",
    "plt.imshow(mask[:, :, slice_idx], cmap=\"gray\")\n",
    "plt.title(\"Binary Mask (Threshold > 0.2)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae2ba10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Find the number of subjects for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45913a19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data.csv\")  \n",
    "df=df[df['imgincl_t1w_include']==1]\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "mean_img=image.mean_img(\"average_map.nii\")\n",
    "mean_data = mean_img.get_fdata().flatten()\n",
    "\n",
    "# Compute correlation for each image\n",
    "images=[]\n",
    "meta_data=[]\n",
    "\n",
    "for _,s in df.iterrows():\n",
    "    d=s['src_subject_id']\n",
    "    t=s['scan_session']\n",
    "    path=datapath+d+timepoint+t\n",
    "    file_path=os.path.join(path,'smwc1pT1.nii')\n",
    "    img=nib.load(file_path).get_fdata()\n",
    "    img_data = img.flatten()  # Flatten current image\n",
    "    corr, _ = pearsonr(img_data, mean_data)  # Compute Pearson correlation\n",
    "    if corr>0.85:\n",
    "        images.append(nib.load(file_path).get_fdata())\n",
    "        meta_data.append(s)\n",
    "print(len(images))\n",
    "print(len(meta_data))\n",
    "\n",
    "filename='Corr_Data.csv'\n",
    "meta_data_df=pd.DataFrame(meta_data)\n",
    "meta_data_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969a735",
   "metadata": {},
   "source": [
    "Neurocombat for the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303d78c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "datapath='/data/neuromark2/Data/ABCD/Data_BIDS_5/Raw_Data/'\n",
    "timepoint=\"/Baseline/\"\n",
    "meta_data= pd.read_csv(\"Corr_Data.csv\")  \n",
    "images=[]\n",
    "for _,s in meta_data.iterrows():\n",
    "    d=s['src_subject_id']\n",
    "    t=s['scan_session']\n",
    "    path=datapath+d+timepoint+t\n",
    "    file_path=os.path.join(path,'smwc1pT1.nii')\n",
    "    images.append(nib.load(file_path).get_fdata()) \n",
    "stacked_image = np.stack(images, axis=-1) \n",
    "\n",
    "print(stacked_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806e21e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "path=datapath+d+timepoint+t\n",
    "first_img = nib.load(os.path.join(path,'smwc1pT1.nii')) \n",
    "stacked_img = nib.Nifti1Image(stacked_image,first_img.affine,header=first_img.header)\n",
    "nib.save(stacked_img, 'brain_images_abcd.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1ed63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from neuroCombat import neuroCombat\n",
    "\n",
    "nii_img = nib.load(\"brain_images_abcd.nii\")  \n",
    "images_4d = nii_img.get_fdata()  \n",
    "\n",
    "X, Y, Z, num_subjects = images_4d.shape\n",
    "num_voxels = X * Y * Z  \n",
    "\n",
    "images_2d = images_4d.reshape(-1, num_subjects)  # Shape: (num_voxels, num_subjects)\n",
    "\n",
    "meta_data_df = pd.read_csv(\"Corr_Data.csv\") \n",
    "site_info = meta_data_df[\"site_id_l\"].values \n",
    "\n",
    "assert len(site_info) == num_subjects, \"Mismatch: site_info and number of subjects\"\n",
    "\n",
    "# Create DataFrame for neuroCombat\n",
    "covars = pd.DataFrame({'site': site_info.astype(str)})  \n",
    "\n",
    "# Convert data type to float32 for compatibility\n",
    "images_2d = images_2d.astype(np.float32)\n",
    "\n",
    "# Apply neuroCombat for harmonization\n",
    "harmonized_data = neuroCombat(dat=images_2d, covars=covars, batch_col='site')\n",
    "\n",
    "# Convert back to 4D NIfTI image\n",
    "harmonized_4d = harmonized_data['data'].reshape(X, Y, Z, num_subjects)\n",
    "\n",
    "# Save the harmonized image \n",
    "harmonized_img = nib.Nifti1Image(harmonized_4d, affine=nii_img.affine, header=nii_img.header)\n",
    "nib.save(harmonized_img, \"harmonized_brain_images_abcd.nii\")\n",
    "print(\"Shape: \",harmonized_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2058b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "mask_img=nib.load('mask.nii')\n",
    "stacked_image=nib.load('harmonized_brain_images_abcd.nii')\n",
    "print(stacked_image.shape)\n",
    "masked_data = apply_mask(stacked_image, mask_img)\n",
    "\n",
    "np.save(\"masked_data_abcd.npy\", masked_data)\n",
    "masked_data.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
